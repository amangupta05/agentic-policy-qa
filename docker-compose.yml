version: "3.9"

services:
  vectordb:
    image: qdrant/qdrant:latest
    ports: ["6333:6333"]

  redis:
    image: redis:7
    ports: ["6379:6379"]

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./infra/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    ports: ["9090:9090"]

  grafana:
    image: grafana/grafana:latest
    ports: ["3000:3000"]
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin

  vllm:
    image: vllm/vllm-openai:latest
    command:
      - --model
      - TinyLlama/TinyLlama-1.1B-Chat-v1.0
      - --dtype
      - float16
      - --max-model-len
      - "2048"
      - --max-num-batched-tokens
      - "2048"
      - --kv-cache-dtype
      - fp8
      - --gpu-memory-utilization
      - "0.80"
      - --enforce-eager
      - --swap-space
      - "4"
    env_file: [.env]
    environment:
      HUGGING_FACE_HUB_TOKEN: ${HUGGING_FACE_HUB_TOKEN}
      HF_HOME: /root/.cache/huggingface
      VLLM_ATTENTION_BACKEND: FLASHINFER
    ports: ["8000:8000"]
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8000/v1/models"]
      interval: 10s
      timeout: 5s
      retries: 12
      start_period: 30s


  gateway:
    image: ghcr.io/placeholder/gateway:dev
    build: ./services/gateway
    env_file: [.env]
    ports: ["8080:8080"]
    environment:
      RETRIEVER_URL: http://retriever:9000
      VLLM_URL: http://vllm:8000
      RERANK_MIN_SCORE: "0"
      RERANK_TOP_K_POST: "1"
      RETRIEVER_TOP_K: "8"
    depends_on:
      vllm:
        condition: service_healthy
      retriever:
        condition: service_started
      reranker:
        condition: service_healthy
      vectordb:
        condition: service_started
      redis:
        condition: service_started

  retriever:
    build: ./services/retriever
    image: agentic-policy-qa-retriever:latest
    env_file: [.env]
    environment:
      QDRANT_URL: http://vectordb:6333
      COLLECTION: policies
      EMBED_MODEL: sentence-transformers/all-MiniLM-L6-v2
      TOP_K: "5"
      RERANKER_MODEL: cross-encoder/ms-marco-MiniLM-L-6-v2
      RERANK_OVERFETCH: "20"
      EF_SEARCH: "512"
    depends_on: [vectordb]
    ports: ["9000:9000"]
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:9000/health"]
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 5s

  reranker:
    build: ./services/reranker
    env_file: [.env]
    ports: ["9100:9100"]
    depends_on: [retriever]
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:9100/health"]
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 5s

  agents:
    build: ./services/agents
    profiles: ["agents"]
